{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch Data From yfinance and save it into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "companies = {\n",
    "    \"COMPANY NAME\": \"TICKER\"\n",
    "    # add more company names and tickers\n",
    "}\n",
    "\n",
    "def fetch_stock_data(tickers):\n",
    "    all_data = []\n",
    "\n",
    "    for company, ticker in tickers.items():\n",
    "        print(f\"Fetching data for {company} ({ticker})...\")\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            hist = stock.history(period=\"max\")  \n",
    "\n",
    "            hist['Company'] = company\n",
    "            hist['Ticker'] = ticker  \n",
    "            hist.reset_index(inplace=True)\n",
    "\n",
    "            all_data.append(hist)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {company} ({ticker}): {e}\")\n",
    "\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "def save_data_to_csv(data, filename='stock_data.csv'):\n",
    "    data.to_csv(filename, index=False)\n",
    "    print(f\"Stock data saved to {filename}\")\n",
    "\n",
    "def main():\n",
    "    stock_data = fetch_stock_data(companies)\n",
    "    save_data_to_csv(stock_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Stock dataset and News dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code may need changes according to the dataset field names. datetime conversion maynot be necessary for your dataset.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def merge_datasets(stock_filename='stock_data.csv', news_filename='Balanced_Sentiment_Dataset.csv', output_filename='merged_data.csv'):\n",
    "\n",
    "    stock_df = pd.read_csv(stock_filename)\n",
    "    news_df = pd.read_csv(news_filename)\n",
    "\n",
    "    stock_df['Date'] = pd.to_datetime(stock_df['Date'], errors='coerce', utc=True).dt.tz_localize(None).dt.date\n",
    "    news_df['DATE'] = pd.to_datetime(news_df['DATE'], errors='coerce').dt.date\n",
    "\n",
    "    news_df = news_df.rename(columns={'DATE': 'Date'})\n",
    "\n",
    "    stock_df['Company'] = stock_df['Company'].str.lower()\n",
    "    news_df['COMPANY NAME'] = news_df['COMPANY NAME'].str.lower()\n",
    "\n",
    "    merged_df = pd.merge(news_df, stock_df, left_on=['Date', 'COMPANY NAME'], right_on=['Date', 'Company'], how='left')\n",
    "\n",
    "    missing_stock_data = merged_df[merged_df['Open'].isna()]\n",
    "    print(f\"Rows with missing stock data before filling: {missing_stock_data.shape[0]}\")\n",
    "\n",
    "    ticker_mapping = stock_df[['Company', 'Ticker']].drop_duplicates().set_index('Company')['Ticker'].to_dict()\n",
    "    merged_df['Ticker'] = merged_df['Ticker'].fillna(merged_df['COMPANY NAME'].map(ticker_mapping))\n",
    "\n",
    "    for index, row in merged_df[merged_df['Open'].isna()].iterrows():\n",
    "        next_day_data = stock_df[(stock_df['Company'] == row['COMPANY NAME']) & (stock_df['Date'] > row['Date'])]\n",
    "        if not next_day_data.empty:\n",
    "            next_day_row = next_day_data.iloc[0]\n",
    "            merged_df.loc[index, ['Open', 'High', 'Low', 'Close']] = [\n",
    "                next_day_row['Open'], next_day_row['High'], next_day_row['Low'], next_day_row['Close']\n",
    "            ]\n",
    "\n",
    "    missing_stock_data_after = merged_df[merged_df['Open'].isna()]\n",
    "    print(f\"Rows with missing stock data after filling: {missing_stock_data_after.shape[0]}\")\n",
    "\n",
    "    merged_df = merged_df[['COMPANY NAME', 'Ticker', 'Date', 'DETAILS', 'Open', 'High', 'Low', 'Close', 'sentiment_label', 'sentiment_score']]\n",
    "\n",
    "    merged_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Merged data saved to {output_filename}\")\n",
    "\n",
    "merge_datasets()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
